<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | KamAcoma]]></title>
  <link href="http://colca.github.com/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://colca.github.com/"/>
  <updated>2014-02-10T16:31:20-08:00</updated>
  <id>http://colca.github.com/</id>
  <author>
    <name><![CDATA[colca]]></name>
    <email><![CDATA[colca7@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop : Install Hadoop 2.2.0 on CentOS]]></title>
    <link href="http://colca.github.com/blog/2014/02/09/hadoop-install-hadoop-2-dot-2-0-on-centos/"/>
    <updated>2014-02-09T20:12:00-08:00</updated>
    <id>http://colca.github.com/blog/2014/02/09/hadoop-install-hadoop-2-dot-2-0-on-centos</id>
    <content type="html"><![CDATA[<p>Prerequisitive <br>
Download java from : <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a> <br></p>

<p><code>
tar xzf jdk-7u51-linux-x64.gz -C /usr/lib/jvm
</code>
Check java version and create link jdk
<code>
$java --version
...
$ln -s jdk1.7.0_51 jdk
</code></p>

<p>Create User And Group <br>
<code>
$groupadd hadoop
$useradd -g hadoop hduser
$passwd hduser
$su hduser
</code></p>

<p>Setup SSH Certificate <br>
<code>
$ssh-keygen -t rsa -P ''
...
Your identification has been saved in /home/hduser/.ssh/id_rsa.
Your public key has been saved in /home/hduser/.ssh/id_rsa.pub.
...
$cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
$ssh localhost
</code></p>

<p>Install Hadoop <br>
Download hadoop tarball from: <a href="http://archive.apache.org/dist/hadoop/core/hadoop-2.2.0/">http://archive.apache.org/dist/hadoop/core/hadoop-2.2.0/</a>
<code>
$sudo tar -xvzf hadoop-2.2.0.tar.gz -C /user/local
$cd /user/local
$sudo mv hadoop-2.2.0 hadoop
$sudo chown -R hduser:hadoop hadoop
</code></p>

<p>Setup Hadoop Environment Variables
<code>
$cd ~
$vi .bashrc
</code>
Add following:
```</p>

<h1>Hadoop vairables</h1>

<p>export JAVA_HOME=/usr/lib/jvm/jdk
export JRE_HOME=/usr/lib/jvm/jdk/jre
export HADOOP_INSTALL=/usr/local/hadoop
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export PATH=$PATH:$JRE_HOME/bin
export PATH=$PATH:$JAVA_HOME/bin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
```</p>

<p>```
$cd /usr/local/hadoop/etc/hadoop
$vi hadoop-env.sh</p>

<h1>modify JAVA_HOME in file to below</h1>

<p>export JAVA_HOME=/usr/lib/jvm/jdk
```</p>

<p>Relogin with hduser and check hadoop version
<code>
$hadoop version
Hadoop 2.2.0
Subversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768
Compiled by hortonmu on 2013-10-07T06:28Z
Compiled with protoc 2.5.0
From source with checksum 79e53ce7994d1628b240f09af91e1af4
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.2.0.jar
</code></p>

<p>Configure Hadoop
```
$cd /usr/local/hadoop/etc/hadoop
$vi core-site.xml</p>

<h1>paste following between <configuration> tag</h1>

<p><property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
<property>
<name>dfs.permissions</name>
<value>false</value>
</property>
<code>
</code>
$vi yarn-site.xml</p>

<h1>paste following between <configuration> tag</h1>

<p><property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux_services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<code>
</code>
$cd ~
$mkdir -p mydata/hdfs/namenode
$mkdir -p mydata/hdfs/datanode
$cd /usr/local/hadoop/etc/hadoop
$vi hdfs-site.xml</p>

<h1>paste following between <configuration> tag</h1>

<p><property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.namenode.name.dir</name>
<value>file:/home/hduser/mydata/hdfs/namenode</value>
</property>
<property>
<name>dfs.datanode.data.dir</name>
<value>file:/home/hduser/mydata/hdfs/datanode</value>
</property>
```</p>

<p>Format Namenode (Onetime)<br>
<code>
$hadoop namenode -format
</code></p>

<p>Start HDFS processes and Map-Reduce process
```</p>

<h1>HDFS</h1>

<p>$hadoop-daemon.sh start namenode
$hadoop-daemon.sh start datanode</p>

<h1>Map-Reduce</h1>

<p>$yarn-daemon.sh start resourcemanager
$yarn-daemon.sh start nodemanager
$mr-jobhistory-daemon.sh start historyserver
```</p>

<p>Verifying Installation <br>
<code>
$jps
1565 JobHistoryServer
1037 DataNode
960 NameNode
1180 ResourceManager
1420 NodeManager
15250 Jps
</code></p>

<p>Run Hadoop Example <br>
```
$cd /usr/local/hadoop
hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar pi 2 5
Number of Maps  = 2
Samples per Map = 5
Java HotSpot&trade; 64-Bit Server VM warning: You have loaded library /usr/local/hadoop/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It&rsquo;s highly recommended that you fix the library with &lsquo;execstack -c <libfile>&rsquo;, or link it with &lsquo;-z noexecstack&rsquo;.
14/02/09 14:14:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform&hellip; using builtin-java classes where applicable
Wrote input for Map #0
Wrote input for Map #1</p>

<p>&hellip;</p>

<pre><code>    File Input Format Counters
            Bytes Read=236
    File Output Format Counters
            Bytes Written=97
</code></pre>

<p>Job Finished in 11.952 seconds
Estimated value of Pi is 3.60000000000000000000
```</p>

<p>Source:<br> <a href="http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html?m=1">http://codesfusion.blogspot.com/2013/10/setup-hadoop-2x-220-on-ubuntu.html?m=1</a><br>
<a href="http://nextgenhadoop.blogspot.com/2013/10/steps-to-install-hadoop-220-stable.html">http://nextgenhadoop.blogspot.com/2013/10/steps-to-install-hadoop-220-stable.html</a><br>
<a href="http://tecadmin.net/steps-to-install-hadoop-on-centosrhel-6/#">http://tecadmin.net/steps-to-install-hadoop-on-centosrhel-6/#</a> <br></p>
]]></content>
  </entry>
  
</feed>
